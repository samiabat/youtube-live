<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Three.js Example</title>
    <script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>

    <script type="importmap">
      {
        "imports": {
            "three": "https://unpkg.com/three@0.154.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.154.0/examples/jsm/",
            "@pixiv/three-vrm": "/lib/three-vrm.module.js"
        }
      }
    </script>

    <style>
        body {
            margin: 0;
            display: flex;
            height: 100vh;
            background-image: url("img/bg.jpg");
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            display: flex;
            justify-content: center;
            align-items: center;
            align-content: space-around;
        }

        #container {
            display: flex;
            width: 100vw;
            height: 100vh;
        }

        /* Comment Box */
        #comment-box {
            width: 40%; /* Adjust the width as needed */
            height: 58%; /* Adjust the height as needed */
            background-color: #333333; /* Dark background with transparency */
            border-radius: 10px;
            padding: 20px;
            display: flex;
            flex-direction: column;
            overflow: hidden; /* Hide scrollbars */
            font-family: 'Roboto', sans-serif;
            color: white;
            position: relative; /* Ensure positioning is relative to the container */
        }

        /* Header Inside the Comment Box */
        #comment-header {
            padding: 40px;
            padding-bottom: 5px;
            font-size: 38px;
            font-family: 'Noto Sans JP', sans-serif;
            font-weight: bold;
            letter-spacing: 8px;
            text-align: center;
            background: #F471B5; /* Gradient background */
            color: white;
            border-top-left-radius: 10px; /* Apply rounded corners to the top left */
            border-top-right-radius: 10px; /* Apply rounded corners to the top right */
            margin: -20px;
            margin-bottom: 10px; /* Space between header and the decorative section */
        }

        /* Decorative Section Above the Line */
        #decorative-section {
            width: 100%;
            height: 60px; /* Adjust the height for visual impact */
            background: linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0.3)), url('path/to/decorative-pattern.png'); /* Pattern and gradient background */
            background-size: cover;
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-bottom: 10px;
        }

        /* Text in Decorative Section */
        #decorative-text {
            font-size: 18px;
            color: #ffd700; /* Gold color */
            text-shadow: 2px 2px 5px rgba(0, 0, 0, 0.5); /* Text shadow for better readability */
            font-weight: bold;
        }

        /* Live Comments Section Below the Line */
        #comment-content {
            display: flex;
            flex-direction: column;
            gap: 10px; /* Spacing between comments */
            overflow-y: auto; /* Scrollable */
            position: absolute;
            top: 17%; /* Start below the horizontal line */
            left: 0;
            right: 0;
            bottom: 0;
            overflow: auto;
            box-sizing: border-box;
            padding: 20px;
        }

        /* Each Comment Block */
        .comment {
            display: inline-block;
            flex-direction: column;
            padding: 20px 30px;
            background-color: #384152; /* Semi-transparent white for comments */
            border-radius: 5px;
            animation: fade-in 0.5s ease-in-out;
            font-size: 20px;
            overflow: hidden; /* Hide overflow */
            font-family: 'Arial', sans-serif;
        }


        /* Smooth Fade-in Animation for New Comments */
        @keyframes fade-in {
            0% {
                opacity: 0;
                transform: translateY(10px);
            }
            100% {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Author span should be inline and styled */
        .author {
            display: inline;
            color: red; /* Pink for the author's name */
            font-weight: bold;
            margin-right: 5px; /* Adds space between the author and the message */
        }

        /* Message span should follow the author inline */
        .message {
            display: inline;
            color: white;
        }





        #right-side {
            width: 50%; /* Takes up more space now */
            height: 100vh; /* Full height */
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }
    </style>
</head>

<body>

    <div id="comment-box">
        <!-- Header Inside the Comment Box -->
        <div id="comment-header">AI Tuberネロによる雑談配信</div>
    

    
        <!-- Comment Content Below the Line -->
        <div id="comment-content"></div>
    </div>
    

    
    <div id="right-side">
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.9.1/gsap.min.js"></script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { BVHLoader } from 'three/addons/loaders/BVHLoader.js';
        import { VRMLoaderPlugin, VRMUtils, VRM, VRMExpression, VRMExpressionMorphTargetBind  } from '@pixiv/three-vrm';
        import { FontLoader } from 'three/addons/loaders/FontLoader.js';
        import { TextGeometry } from 'three/addons/geometries/TextGeometry.js';

        let mixer = null;
        let joinSpringManager = null;
        let currentVrm = undefined;
        let animationClip;
        let mapAction = new Map();
        let currentBvhFilePath = '';

        const imageFile = new Map();
        var scene = new THREE.Scene();
        var camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 10);
        camera.position.set(0, 1.5, -1.0); // Adjusted to focus on the upper body
        camera.rotation.set(0, Math.PI, 0);

        let now = new Date(new Date().toUTCString());

        const rightSide = document.getElementById('right-side');
        const renderer = new THREE.WebGLRenderer({ alpha: true });

        const targetAspect = document.body.clientWidth / document.body.clientHeight;

        const light = new THREE.DirectionalLight(0xffffff);

        const canvas = document.createElement('canvas');
        const context = canvas.getContext('2d');
        const commentBox = document.getElementById('comment-content');
        const maxVisibleComments = 6; // Maximum number of visible comments

        const gradient = context.createLinearGradient(0, 0, canvas.width, canvas.height);

        const chatbotApiUrl = "http://18.176.84.155:5000/live";
        const speechApiUrl = "http://13.114.188.215:5000/voice";

        const listener = new THREE.AudioListener();
        const sound = new THREE.Audio(listener);
        const audioLoader = new THREE.AudioLoader();

        // Arrays to store multiple animations for each emotion
        const talkingAnimations = ['speak-emotion/Sena_Saotome_talk01_e16.bvh', 'speak-emotion/Sena_Saotome_talk02_e05.bvh', 
                                    'speak-emotion/Sena_Saotome_talk03_e03.bvh', 'speak-emotion/Sena_Saotome_talk04_e03.bvh', 
                                    'speak-emotion/Sena_Saotome_talk05_e01.bvh'];
        const waitingAnimations = ['waiting-emotion/Sena_Saotome_idle01_e06.bvh', 'waiting-emotion/Sena_Saotome_idle02_e08.bvh', 
                                    'cute-emotion/Sena_Saotome_Accent01_e11.bvh'];




        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(rightSide.clientWidth, rightSide.clientHeight);
        rightSide.appendChild(renderer.domElement);

        window.addEventListener('resize', () => {
            renderer.setSize(rightSide.clientWidth, rightSide.clientHeight);
        });



        
        light.position.set(-1, 1, -1).normalize();
        scene.add(light);

        
        // canvas.width = 400; // Adjust size as needed
        // canvas.height = 512; // Adjust size as needed
        
        gradient.addColorStop(0, '#ff6f61'); // Start color (coral)
        gradient.addColorStop(1, '#ffb74d'); // End color (orange)

        
        let commentQueue = []; // Queue for comments that need audio responses
        let unreadMessageQueue = []; // Queue for comments that are not yet processed
        let isProcessingAudio = false; // Flag to indicate if audio is being processed
        let introducedUsers = new Set(); // Set to keep track of introduced users
        let idleInterval; // Interval to handle idle talking
        let isPlaying = false;


        // fetch comments from the api
        async function fetchComments() {
            const eventSource = new EventSource('http://localhost:8000/stream-comments-only');

            eventSource.onmessage = function(event) {
                try {
                    console.log('Raw data received:', event.data); // Log the raw data
                    // Replace single quotes with double quotes to handle JSON format
                    let formattedData = event.data
                        .replace(/(\r\n|\n|\r)/gm, "")  // Remove any line breaks
                        .replace(/'/g, '"'); 

                    const commentData = JSON.parse(formattedData);

                    // Extract author and message
                    const author = commentData.author || 'Anonymous';
                    const  message = commentData.message || '';
                    const autherId = commentData.authorId || '';
                    const status = commentData.status || '';

        
                    handleMessage(author, message, status, false);
                    
                } catch (error) {
                    console.error('Error processing comment data:', error);
                }
            };

            eventSource.onerror = function(event) {
                console.error('Error occurred:', event);
                eventSource.close();
            };
            
        }

        let idleMessageInterval;

        // Single function to handle both unread messages and idle messages
        async function idleMessageHandler() {
            if (unreadMessageQueue.length > 0) {
                console.log(`New messages in the queue, processing messages... ${unreadMessageQueue}`);
            } else if (!isPlaying) {
                console.log('Queue is empty, fetching idle message...');
                const idleComment = "ライブの視聴者にランダムな話題を提供してください/話してください。";  // Identifier for idle messages
                const username = "";     // Default username for idle mode

                try {
                    let { text: idleMessage } = await getChatbotResponse(idleComment, username, 4);

                    if (idleMessage) {
                        console.log(`Idle message from chatbot: ${idleMessage}`);
                        unreadMessageQueue.push({ author: 'Chatbot', message: idleMessage, status: 'old' });
                    } else {
                        console.error("No idle message received from the chatbot.");
                    }
                } catch (error) {
                    console.error("Error fetching idle message from chatbot:", error);
                }
            }
        }

        // Function to start the interval for idle messages
        function startIdleMessageHandler() {
            idleMessageInterval = setInterval(idleMessageHandler, 10000);  // Run every 10 seconds
        }

        fetchComments();

        // Call this to start the idle message handling process
        startIdleMessageHandler();


        // handle message.
        function handleMessage(author, message, status, isIdle) {
            if (isIdle) {
                // put in the unreadComment array 
                unreadMessageQueue.push({ author, message, status });
            } else {
                // put the message in the unreadComment array and also display it to the screen. add the to the comment box or comment queue
                // status is new or old
                unreadMessageQueue.push({ author, message, status });
                addCommentToBox(author, message);

                commentQueue.push({ author, message, status });
            }
            
        }


        // generate speech for comments
        async function generateSpeech(text) {
            const params = {
                text: text,
                model_id: 12,
                speaker_name: "A-amazinGood",
                speaker_id: 0,
                sdp_ratio: 0.2,
                noise: 0.6,
                noisew: 0.8,
                length: 1,
                language: "JP",
                auto_split: "true",
                split_interval: 0.5,
                assist_text_weight: 1,
                style: "Neutral",
                style_weight: 1,
                pitch_scale: 1,
                intonation_scale: 1
            };

            const queryString = new URLSearchParams(params).toString();
            const requestUrl = `${speechApiUrl}?${queryString}`;

            try {
                const response = await fetch(requestUrl, { method: 'POST' });

                if (response.ok) {
                    const audioData = await response.arrayBuffer();
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();

                    // Clone the ArrayBuffer if you intend to use it more than once
                    const clonedBuffer = audioData.slice(0); // Ensure you don't reuse the original ArrayBuffer

                    const buffer = await audioContext.decodeAudioData(clonedBuffer);

                    const duration = buffer.duration; // Get the duration from the decoded audio data

                    console.log("Speech generated successfully. Duration:", duration);

                    return { audioData, duration };

                } else if (response.status === 405) {
                    console.log("Method not allowed, retrying in 60 seconds...");
                    setTimeout(() => generateSpeech(text), 50000); // Retry after 60 seconds
                } else {
                    console.error("An unexpected error occurred:", response.statusText);
                    return { audioData: null, duration: 0 }; // Return 0 sec duration on failure
                }

            } catch (error) {
                console.error("Error fetching or decoding audio data:", error);
                return { audioData: null, duration: 0 }; // Return 0 sec duration on error
            }
        }


        // Function to play audio and dynamically adjust the interval
        async function playAudio() {
            if (isPlaying) {
                console.log('Audio is already playing, skipping...');
                return; // Prevent overlapping audio
            }

            if (unreadMessageQueue.length === 0) {
                console.log('No unread messages, checking again in 10 seconds');
                setTimeout(playAudio, 5000); // Retry checking after 5 seconds if there are no unread messages
                return;
            }

            // Get the next comment to process
            const { author, message, status } = unreadMessageQueue.shift();
            console.log(`Processing message from: ${author}, status: ${status}`);

            const chatbotResponse = await getChatbotResponse(message, author, 1);

            console.log(`Chatbot response for ${author}: ${chatbotResponse.text}`);

            try {
                // Generate speech for the comment
                
                const { audioData, duration } = await generateSpeech(chatbotResponse.text);


                if (audioData) {
                    isPlaying = true;
                    simulateSpeaking(); // Start mouth animation
                    switchEmotions('talking');

                    // Check if the user is new and play intro audio first
                    if (status === 'new') {
                        const introAudioUrl = 'intro.wav'; // Replace with the actual path to the intro audio file
                        try {
                            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                            const response = await fetch(introAudioUrl);
                            const introAudioData = await response.arrayBuffer();
                            const introBuffer = await audioContext.decodeAudioData(introAudioData);
                            const introSource = audioContext.createBufferSource();
                            introSource.buffer = introBuffer;
                            introSource.connect(audioContext.destination);
                            introSource.start(0);

                            console.log('Intro audio playing for new user.');

                            // Wait for the intro audio to finish
                            await new Promise(resolve => {
                                introSource.onended = () => {
                                    console.log('Intro audio finished.');
                                    resolve();
                                };
                            });
                        } catch (error) {
                            console.error('Error playing intro audio:', error);
                        }
                    }

                    // Play the generated speech after the intro (if applicable)
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const buffer = await audioContext.decodeAudioData(audioData);
                    const source = audioContext.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioContext.destination);
                    source.start(0);

                    // Wait for the generated speech audio to finish
                    await new Promise(resolve => {
                        source.onended = () => {
                            stopMouthAnimation(); // Stop mouth animation
                            switchEmotions('waiting');
                            isPlaying = false;
                            resolve();
                        };
                    });

                    // After the audio finishes, check for the next message
                    playAudio();
                }
            } catch (error) {
                console.error('Error processing the comment:', error);
                isPlaying = false;
                stopMouthAnimation(); // Ensure animation stops in case of error
                switchEmotions('waiting');
                playAudio(); // Retry the next audio processing after an error
            }
        }


        playAudio(); // Start the audio processing
        // Function to add comments to the box
        function addCommentToBox(author, message) {
            const comment = document.createElement('div');
            comment.className = 'comment';

            // Create spans for the author and message
            const authorSpan = document.createElement('span');
            authorSpan.className = 'author';
            authorSpan.style.color = 'pink';  // Styling for the author
            authorSpan.style.fontWeight = 'bold';
            authorSpan.textContent = author + ": ";

            const messageSpan = document.createElement('span');
            messageSpan.className = 'message';
            messageSpan.textContent = message;

            // Append both spans to the comment div
            comment.appendChild(authorSpan);
            comment.appendChild(messageSpan);

            // Append the new comment to the comment-content container
            const commentBox = document.getElementById('comment-content');
            commentBox.appendChild(comment);

            // Remove the oldest comment if necessary
            const comments = commentBox.querySelectorAll('.comment');
            if (comments.length > maxVisibleComments) {
                commentBox.removeChild(comments[0]); // Remove the first comment
            }

            // Scroll to the latest comment
            commentBox.scrollTop = commentBox.scrollHeight;
        }
                

        // get a response for comments from the chatbot
        async function getChatbotResponse(comment, username, id) {
            const payload = {
                body: {
                    event_id: id,
                    game_id: null,
                    character_name: "nekohime",
                    username: username,
                    userid: "Live",
                    comment: comment,
                    giftid: null,
                    gender: "male",
                    embedding: null,
                    language: "Japanese"
                }
            };

            try {
                const response = await fetch(chatbotApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (response.ok) {
                    const responseData = await response.json();
                    console.log("response data from the chatbot:",  responseData, comment, username)
                    return {
                        text: responseData.body?.text || 'No response from chatbot',
                        emotion: responseData.body?.EmotionalB || responseData.body?.EmotionalA || "3" // Replace EmotionalB with the actual key
                    };
                } else {
                    console.error(`Chatbot request failed with status: ${response.status}`);
                    return null;
                }
            } catch (error) {
                console.error(`Failed to get chatbot response: ${error}`);
                return null;
            }
        }

        let emotionSwitchInterval;

        // Function to get a random animation (for both talking and waiting emotions)
        function getRandomAnimation(animations) {
            const randomIndex = Math.floor(Math.random() * animations.length);
            return animations[randomIndex];
        }

        // Unified function to switch between emotions dynamically based on the type
        function switchEmotions(type) {
            const animations = type === 'talking' ? talkingAnimations : waitingAnimations;

            // Clear any existing interval to avoid overlap
            clearInterval(emotionSwitchInterval);

            // Start switching emotions based on the type (talking or waiting)
            emotionSwitchInterval = setInterval(() => {
                const randomAnimation = getRandomAnimation(animations);
                applyAnimation(randomAnimation, type);
                console.log(`Applied ${type} emotion: ${randomAnimation}`);
            }, 3000); // Switch emotions every 3 seconds (adjust this interval as needed)
        }



        loadVrm();
        function loadVrm() {

            const loader = new GLTFLoader();

            loader.register((parser) => {
                return new VRMLoaderPlugin(parser);
            });

            loader.load(
                `models/L001_cos01.vrm`,
                (gltf) => {
                    const vrm = gltf.userData.vrm;
                    VRMUtils.removeUnnecessaryVertices(gltf.scene);
                    VRMUtils.removeUnnecessaryJoints(gltf.scene);
                    vrm.scene.traverse((obj) => {
                        obj.frustumCulled = false;
                    });
                    scene.add(vrm.scene);
                    currentVrm = vrm;

                    vrm.scene.position.set(0.015, -1.85, 0.2); // Keep the same position
                    vrm.scene.rotation.y = 0;
                    vrm.scene.rotation.x = Math.PI / 36;
                    vrm.scene.scale.set(4.5, 2.3, 4.5); // Further increase the X and Z axes scale to widen the face more

                    joinSpringManager = vrm.springBoneManager;

                    if (currentVrm) {
                        switchEmotions('waiting');
                        
                    }
                      // Adjust the delay if needed
                    // setTimeout(() => {
                    //     console.log('success');
                    // }, 3000);
                },
                (progress) => { },
                (error) => console.error(error)
            );
        }
        

        function simulateSpeaking() {
            if (!currentVrm || !currentVrm.expressionManager) {
                console.error("VRM or expression manager is not loaded.");
                return;
            }

            const vowelExpressions = ['aa', 'ih', 'ee', 'ou', 'oh'];
            let currentExpressionIndex = 0;
            let intensity = 0;
            let intensityDirection = 1;
            let animationFrame;

            const updateExpression = () => {
                if (!isPlaying) {
                    // Stop the animation if speaking has stopped
                    stopMouthAnimation();
                    return;
                }

                // Reset all expressions to prevent blending issues
                Object.keys(currentVrm.expressionManager.expressions).forEach(expressionName => {
                    currentVrm.expressionManager.setValue(expressionName, 0);
                });

                // Increase intensity change speed to make the mouth animation faster
                const intensityChangeRate = 0.15; // Increased from 0.05 to 0.15 for faster transitions
                intensity += intensityChangeRate * intensityDirection;

                // Reverse intensity direction if bounds are reached
                if (intensity >= 1 || intensity <= 0) {
                    intensityDirection *= -1;
                    intensity = Math.max(0, Math.min(1, intensity)); // Clamp intensity between 0 and 1
                }

                // Apply the current expression with the calculated intensity
                const currentExpression = vowelExpressions[currentExpressionIndex];
                currentVrm.expressionManager.setValue(currentExpression, intensity);

                // Switch to the next expression when intensity fades out
                if (intensity <= 0) {
                    currentExpressionIndex = (currentExpressionIndex + 1) % vowelExpressions.length;
                }

                // Request the next frame for smoother animation
                animationFrame = requestAnimationFrame(updateExpression);
            };

            // Start the expression update loop
            updateExpression();
        }



        function stopMouthAnimation() {

            // Ensure all mouth-related expressions are reset to 0
            if (currentVrm && currentVrm.expressionManager) {
                const mouthExpressions = ['aa', 'ih', 'ee', 'ou', 'oh'];
                mouthExpressions.forEach(expressionName => {
                    currentVrm.expressionManager.setValue(expressionName, 0);
                });
                // After stopping, return to neutral emotion
            }
        }

        setInterval(stopMouthAnimation, 10000);

        

        

        const emotions = {
            happy: ['happy'],       // Single expression
            relaxed: ['relaxed'],   // Single expression
            neutral: ['neutral'],   // Single expression
            angry: ['angry'],       // Single expression
            sad: ['sad']            // Single expression
        };

        

        

        function applyEmotion(emotion) {
            if (!currentVrm || !currentVrm.expressionManager) {
                console.error("VRM or expression manager is not loaded.");
                return;
            }

            // Verify the reset state by logging the current values of all expressions
            Object.keys(currentVrm.expressionManager.expressions).forEach(expressionName => {
                const currentValue = currentVrm.expressionManager.getValue(expressionName);
            });

            // Optionally, set the VRM model back to a neutral state
            currentVrm.expressionManager.setValue("sad", 0);
            currentVrm.expressionManager.setValue("happy", 0);
            currentVrm.expressionManager.setValue("relaxed", 0);
            currentVrm.expressionManager.setValue("sad", 0);
            currentVrm.expressionManager.setValue("angry", 0);
            currentVrm.expressionManager.setValue('neutral', 1); // 'neutral' can be changed to a suitable expression if available.
            currentVrm.expressionManager.update();

            
            // Apply other emotions without mouth adjustment
            if (emotions[emotion]) {
                emotions[emotion].forEach(expressionName => {
                    currentVrm.expressionManager.setValue(expressionName, 1);
                });
                console.log(`Applying emotion: ${emotion}`);
            } else {
                console.error(`Emotion ${emotion} not found.`);
            }
            
        }




        let isProcessed = true;
        let lastTimeUpdateMotion = 0;

        let isFading = false;
        let loading = false;
        let currentAction;
        let pendingAnimation = null;

        function applyAnimation(bvhFilePath, animationName ) {      
            if (!currentVrm) return; // VRMがロードされていなければ何もしない
            currentVrm.lastTimeUpdateMotion = 0;
            currentVrm.loading = false;
            currentVrm.isFading = false;
            currentVrm.currentAction = null;
            currentVrm.pendingAnimation = null;
            if (currentVrm.currentBvhFilePath === bvhFilePath) return;
            if (mapAction.get(bvhFilePath)) {
                if (!mixer) {
                    mixer = new THREE.AnimationMixer(currentVrm.scene);
                    currentVrm.mixer = mixer;
                }
                if (currentVrm.isFading || currentVrm.loading) {

                    currentVrm.pendingAnimation = bvhFilePath;
                    return;
                }
                synchronizeCrossFade(bvhFilePath, 1, currentVrm);
            } else {
                currentVrm.loading = true;
                const loader1 = new BVHLoader();
                loader1.load(bvhFilePath, function (result) {
                    for (let i = result.clip.tracks.length; i--;) {
                        let track = result.clip.tracks[i];
                        var value = [];
                        var extension = track.name.split('.').pop();
                        let map = new Map(Object.entries(currentVrm.humanoid.humanBones));
                        var exists = Array.from(map.keys()).find(obj => { 
                            return track.name.toLowerCase().includes(obj.toLowerCase())});
                        if(exists){
                            if(extension){
                                track.name = `${map.get(exists).node.name}.${extension}`
                            } else {
                                track.name = `${map.get(exists).node.name}`
                            }
                        };
                        if (track.name.toLowerCase().match(/.+\.([^?]+)(\?|$)/)[1] === "position") {
                            if ([].includes(track.name)) {
                                continue;
                            } else {
                                result.clip.tracks.splice(i, 1);
                            }
                        } else {
                            if ([].includes(track.name)) {
                                result.clip.tracks.splice(i, 1);
                            } else {
                                for (var trackValue of track.values) {
                                    var trackValueNew = trackValue;
                                    if (track.values.indexOf(trackValue) % 4 == 3) {
                                        trackValueNew = -trackValue;
                                    }
                                    if (track.values.indexOf(trackValue) % 4 == 1) {
                                        trackValueNew = -trackValue;
                                    }
                                    value.push(trackValueNew);
                                }
                            }
                            track.values = value;
                            track.values.splice(0, 4);
                            track.times = track.times.subarray(1);
                        }
                    }
                    if (!mixer) {
                        mixer = new THREE.AnimationMixer(currentVrm.scene);
                        currentVrm.mixer = mixer;
                    }
                    currentVrm.animationClip = result.clip;
                    currentVrm.animationClip.name = bvhFilePath;
                    currentVrm.animationClip.duration = calculateDuration(result.clip);
                    console.log('duration', currentVrm.animationClip.duration);

                    currentVrm.loading = false;
                    if (currentVrm.isFading || currentVrm.loading) {

                        currentVrm.pendingAnimation = bvhFilePath;
                        return;
                    }
                    mapAction.set(bvhFilePath, currentVrm.animationClip);

                    synchronizeCrossFade(bvhFilePath, 1, currentVrm);
                });
            }
            currentVrm.currentBvhFilePath = bvhFilePath;
        }

        function getIndex(nameKey){
            var index = -1;
            currentVrm.scene.traverse((obj) => {
                if(index >= 0) return;
                if(obj.isMesh && obj.name.toLowerCase().includes('face')){
                    console.log(obj.geometry.userData['targetNames']);
                    if(obj.geometry.userData['targetNames']){
                        var thisIndex = obj.geometry.userData['targetNames'].indexOf(nameKey)
                        console.log(thisIndex);
                        index = thisIndex;
                    }
                }
            });
            return index;
        }

        function synchronizeCrossFade(bvhFilePath, duration) {
            var currentDate = new Date().getTime();
            if ((currentDate - lastTimeUpdateMotion) < 1000) {
                return;
            }
            lastTimeUpdateMotion = currentDate;
            console.log(new Date().toISOString());
            const loadAndApply = (clip) => {
                if (currentAction) {
                    currentAction.fadeOut(duration);
                    isFading = true;
                    console.log(duration * 1000);
                    setTimeout(() => {
                        console.log('pendingAnimation');
                        isFading = false;
                        if (pendingAnimation) {
                            applyAnimation(
                                pendingAnimation,
                                pendingAnimation.animationName
                            );
                            pendingAnimation = null;
                        }
                    }, duration * 1000);
                }

                const newAction = mixer.clipAction(clip);
                newAction.setLoop(THREE.LoopRepeat);
                newAction.clampWhenFinished = false;
                console.log('playEndAction', new Date());
                newAction.reset();
                newAction.fadeIn(duration);
                newAction.play();

                currentAction = newAction;
            };

            if (mapAction.has(bvhFilePath)) {
                loadAndApply(mapAction.get(bvhFilePath));
            }
        }

        function isSameType(pendingAnimation) {
            var pendingNotNumber = pendingAnimation.replace(/[0-9]/g, '').replace('.bvh', '');
            var currentNotNumber = currentBvhFilePath.replace(/[0-9]/g, '').replace('.bvh', '');
            console.log(pendingNotNumber === currentNotNumber);
            return pendingNotNumber === currentNotNumber;
        }

        function calculateDuration(bvhClip) {
            const frames = bvhClip.tracks[0].times.length;
            const frameTime = bvhClip.tracks[0].times[1] - bvhClip.tracks[0].times[0];
            return frames * frameTime;
        }

        animate();
        function animate() {

            setTimeout(() => {
                animate();
            }, 0.02 * 1000)

            renderer.render(scene, camera);

            if (mixer) mixer.update(0.02 );

            if (joinSpringManager) joinSpringManager.update(10 / 1000);

            if (currentVrm && currentVrm.expressionManager) {
                currentVrm.expressionManager.update();
            }

        }
    
    </script>
    
</body>

</html>